{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffa0b1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c3910f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('carbonated_soft_drinks.csv');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09f803dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bottle Coke Classic 20oz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bottle Coke Diet 20oz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20oz Fountain Beverage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bottle Pepsi 20oz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32oz Fountain Beverage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bottle Mountain Dew 20oz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bottle Coke Zero 20oz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bottle Dr. Pepper 20oz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Bottle Dr. Pepper Diet 20oz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Diet Pepsi 20oz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     item_name\n",
       "0     Bottle Coke Classic 20oz\n",
       "1        Bottle Coke Diet 20oz\n",
       "2       20oz Fountain Beverage\n",
       "3            Bottle Pepsi 20oz\n",
       "4       32oz Fountain Beverage\n",
       "5     Bottle Mountain Dew 20oz\n",
       "6        Bottle Coke Zero 20oz\n",
       "7       Bottle Dr. Pepper 20oz\n",
       "8  Bottle Dr. Pepper Diet 20oz\n",
       "9              Diet Pepsi 20oz"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.item_name.nunique()\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aba8474f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(sentence):\n",
    "    \n",
    "    # Basic cleaning\n",
    "    sentence = sentence.strip() ## remove whitespaces\n",
    "    sentence = sentence.lower() ## lowercase \n",
    "    sentence = ''.join(char for char in sentence if not char.isdigit()) ## remove numbers\n",
    "    \n",
    "    removables = ['bottle','bvc' ,'can', 'oz', 'ml', 'large', 'diet', 'zero', 'sugar', 'original', 'medium', 'lt', 'fl',\n",
    "                  'soft', 'drink', 'blend', 'canned', 'bl', 'glass', 'soda', 'bvg']\n",
    "    alphabet = list(string.ascii_lowercase)\n",
    "    \n",
    "    for punctuation in string.punctuation:\n",
    "        sentence = sentence.replace(punctuation, '')\n",
    "\n",
    "    word_tokens = word_tokenize(sentence)\n",
    "    \n",
    "    # Advanced cleaning\n",
    "    word_tokens = [w for w in word_tokens if w not in removables] ## remove punctuation\n",
    "    word_tokens = [w for w in word_tokens if w not in alphabet]\n",
    "        \n",
    "    cleaned_sentence = ' '.join(word for word in word_tokens)\n",
    "    \n",
    "    return cleaned_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a07b389",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['item_name_clean'] = data.item_name.apply(cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aec81660",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function returns a list of brand name subset found in item_name\n",
    "#If it find nothing it returns an empty string\n",
    "\n",
    "def identify_brand(text):   \n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    brands = ['schweppes', 'sunkist', 'coke', 'coca', 'cola', 'cocacola', 'pepsi', 'topo' 'chico', 'crush', \n",
    "              'fanta', 'mountain' , 'dew', 'canada' ,'dry', 'dr', 'pepper', 'sprite', 'aw', 'stewarts']\n",
    "    brand = [w for w in tokens if w in brands]\n",
    "    return brand\n",
    "\n",
    "#This function returns a string containing identiable brand text found in item_name\n",
    "#If it does not identify then it returns the input itself, namely item_name_clean\n",
    "\n",
    "def identify_brand_str(text):   \n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    brands = ['schweppes', 'sunkist', 'coke', 'coca', 'cola', 'cocacola', 'pepsi', 'topo' 'chico', 'crush', \n",
    "              'fanta', 'mountain' , 'dew', 'canada' ,'dry', 'dr', 'pepper', 'sprite', 'aw', 'stewarts']\n",
    "    brand = [w for w in tokens if w in brands]\n",
    "    \n",
    "    if brand:\n",
    "        return ' '.join(w for w in brand)\n",
    "    else:\n",
    "        return text\n",
    "    \n",
    "def preliminary_label(text):   \n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    brands = ['schweppes', 'sunkist', 'coke', 'coca', 'cola', 'cocacola', 'pepsi', 'topo' 'chico', 'crush', \n",
    "              'fanta', 'mountain' , 'dew', 'canada' ,'dry', 'dr', 'pepper', 'sprite', 'aw', 'stewarts']\n",
    "    brand = [w for w in tokens if w in brands]\n",
    "    coke = ['coke', 'coca', 'cola', 'cocacola']\n",
    "    \n",
    "    if brand:\n",
    "        return ' '.join(w for w in brand)\n",
    "    else:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8fcd044",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['brand'] = data.item_name_clean.apply(identify_brand)\n",
    "data['brands'] = data.item_name_clean.apply(identify_brand_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15d3de8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]                          5768\n",
       "[coke]                      2331\n",
       "[pepsi]                     1611\n",
       "[dew]                       1050\n",
       "[mountain, dew]             1027\n",
       "[dr, pepper]                 821\n",
       "[sprite]                     762\n",
       "[fanta]                      618\n",
       "[canada, dry]                586\n",
       "[coca, cola]                 376\n",
       "[crush]                      369\n",
       "[sunkist]                    329\n",
       "[aw]                         229\n",
       "[schweppes]                  205\n",
       "[cocacola]                   166\n",
       "[stewarts]                   135\n",
       "[cola]                       116\n",
       "[dry]                         77\n",
       "[dr]                          69\n",
       "[pepsi, cola]                 67\n",
       "[mountain]                    34\n",
       "[dew, dew]                    30\n",
       "[coca, cola, coke]            21\n",
       "[mountain, dew, dew]          20\n",
       "[coke, coke]                  17\n",
       "[topochico]                   15\n",
       "[coke, cola]                  12\n",
       "[pepper]                      12\n",
       "[pepsi, dew]                  11\n",
       "[coca]                         9\n",
       "                            ... \n",
       "[schweppes, dry]               7\n",
       "[coke, coca, cola]             6\n",
       "[pepsi, mountain, dew]         6\n",
       "[pepsi, crush]                 5\n",
       "[coke, pepsi]                  4\n",
       "[cocacola, coke]               4\n",
       "[crush, pepsi]                 3\n",
       "[pepsi, cola, cola]            3\n",
       "[coke, sprite]                 3\n",
       "[cola, pepsi]                  3\n",
       "[fanta, fanta]                 3\n",
       "[coca, coke]                   3\n",
       "[coca, cola, sprite]           2\n",
       "[cola, cola]                   2\n",
       "[cocacola, sprite]             2\n",
       "[cola, coke]                   2\n",
       "[pepsi, dr, pepper]            2\n",
       "[pepsi, schweppes]             2\n",
       "[dr, pepper, cola]             1\n",
       "[pepsi, aw]                    1\n",
       "[dry, cola]                    1\n",
       "[pepsi, sunkist]               1\n",
       "[fanta, coke]                  1\n",
       "[coke, cocacola]               1\n",
       "[dr, pepper, sunkist]          1\n",
       "[coke, coke, sprite]           1\n",
       "[coke, fanta]                  1\n",
       "[fanta, cola]                  1\n",
       "[coca, cola, coca, cola]       1\n",
       "[coke, dr, pepper]             1\n",
       "Name: brand, Length: 62, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#62 unique values when leaving unidentifiable text empty\n",
    "pd.set_option('display.min_rows', 100)\n",
    "data.brand.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6c32a24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "coke                             2331\n",
       "pepsi                            1611\n",
       "dew                              1050\n",
       "mountain dew                     1027\n",
       "dr pepper                         821\n",
       "sprite                            762\n",
       "fanta                             618\n",
       "canada dry                        586\n",
       "coca cola                         376\n",
       "crush                             369\n",
       "fountain                          343\n",
       "sunkist                           329\n",
       "                                  258\n",
       "aw                                229\n",
       "schweppes                         205\n",
       "cocacola                          166\n",
       "stewarts                          135\n",
       "up                                128\n",
       "cola                              116\n",
       "seagrams ginger ale                99\n",
       "sierra mist                        79\n",
       "dry                                77\n",
       "fountain beverage                  75\n",
       "dr                                 69\n",
       "squirt                             68\n",
       "pepsi cola                         67\n",
       "barqs root beer                    66\n",
       "bottled                            57\n",
       "mug root beer                      56\n",
       "ginger ale                         46\n",
       "                                 ... \n",
       "md fountain beverage                1\n",
       "mnt dw                              1\n",
       "up suga                             1\n",
       "add refill fountain                 1\n",
       "cv                                  1\n",
       "cafe                                1\n",
       "zaco                                1\n",
       "beer stella                         1\n",
       "beer craft old capital ale          1\n",
       "ah baking lb each                   1\n",
       "black cherry vernors                1\n",
       "craft sodas coconut mang            1\n",
       "pepsii wild cherry                  1\n",
       "package                             1\n",
       "nss poppi ginger lime               1\n",
       "mtd rise orange breeze              1\n",
       "sprecher                            1\n",
       "watermelon                          1\n",
       "sierra mist pk                      1\n",
       "bev twist mist                      1\n",
       "fountain bev byoc                   1\n",
       "spring pale ale                     1\n",
       "lrg fountain                        1\n",
       "nws topo chico grapefruit btl       1\n",
       "mtd rise peach mango                1\n",
       "rootbeer barqs                      1\n",
       "sm fountain beverage                1\n",
       "seagram gingerale                   1\n",
       "pl crsh spk frt pnc                 1\n",
       "sw                                  1\n",
       "Name: brands, Length: 2560, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2560 values when keeping item_name_clean\n",
    "data.brands.nunique()\n",
    "data.brands.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9b8ba88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-01 05:59:43.149832: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coke ORG\n",
      "Classic PRODUCT\n"
     ]
    }
   ],
   "source": [
    "#NER model considered (which does not always work very well in this case)\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "doc = nlp(\"Coke Classic\")\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec0d06c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pepsi ORG\n",
      "nsm squirt btl ORG\n",
      "coke ORG\n",
      "coke ORG\n",
      "pepsi ORG\n",
      "pepsi ORG\n",
      "bundaberg GPE\n",
      "coke ORG\n",
      "sodas ORG\n",
      "barqs ORG\n",
      "pepsi ORG\n",
      "canada GPE\n",
      "fanta GPE\n",
      "coca cola ORG\n",
      "pepsi ORG\n",
      "pepsi ORG\n",
      "pepsi ORG\n",
      "pibb xtra PERSON\n",
      "coke ORG\n",
      "coke ORG\n",
      "sierra mist ORG\n",
      "cola ORG\n",
      "coke ORG\n",
      "fanta GPE\n",
      "pepsi ORG\n",
      "cola ORG\n",
      "coke ORG\n",
      "coke ORG\n",
      "coke ORG\n",
      "canada GPE\n",
      "coke ORG\n",
      "coke ORG\n",
      "canada GPE\n",
      "canada GPE\n",
      "coke ORG\n",
      "coke ORG\n",
      "pepsi ORG\n",
      "coke ORG\n",
      "coca cola ORG\n",
      "pomegrana ORG\n"
     ]
    }
   ],
   "source": [
    "#applying the model to a sample from data.brands \n",
    "\n",
    "sample = data.brands.sample(100) \n",
    "for sm in sample:\n",
    "    doc = nlp(sm)\n",
    "    for ent in doc.ents:\n",
    "        print(ent.text, ent.label_)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3e19a72f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'csv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [34], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m TRAIN_DATA \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msupervised_tagged_dataset.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m csvfile:\n\u001b[0;32m---> 14\u001b[0m     reader \u001b[38;5;241m=\u001b[39m \u001b[43mcsv\u001b[49m\u001b[38;5;241m.\u001b[39mreader(csvfile)\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m reader:\n\u001b[1;32m     16\u001b[0m         string, tags \u001b[38;5;241m=\u001b[39m row\n",
      "\u001b[0;31mNameError\u001b[0m: name 'csv' is not defined"
     ]
    }
   ],
   "source": [
    "training_data = pd.read_csv('supervised_tagged_dataset.csv')\n",
    "#format required:\n",
    "\n",
    "# Create a training data set\n",
    "TRAIN_DATA = [\n",
    "    (\"Who is Shaka Khan?\", {\"entities\": [(7, 17, \"PERSON\")]}),\n",
    "    (\"I love London and Berlin.\", {\"entities\": [(7, 13, \"GPE\"), (18, 24, \"GPE\")]}),\n",
    "    (\"Apple is looking at buying U.K. startup for $1 billion\", \n",
    "     {\"entities\": [(0, 5, \"PRODUCT\"), (44, 54, \"GPE\"), (67, 76, \"MONEY\")]})\n",
    "]\n",
    "\n",
    "import csv\n",
    "\n",
    "TRAIN_DATA = []\n",
    "with open(\"supervised_tagged_dataset.csv\") as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for row in reader:\n",
    "        string, tags = row\n",
    "        words = string.split()\n",
    "        word_tags = tags.split()\n",
    "        TRAIN_DATA.append(list(zip(words, word_tags)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69d9ae7-27ee-4c4f-9308-8b940e3e6c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.util import minibatch, compounding\n",
    "\n",
    "# Load a pre-trained model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Add a custom NER component to the pipeline\n",
    "ner = nlp.get_pipe(\"ner\")\n",
    "\n",
    "# Define the labels you want to predict\n",
    "LABELS = [\"ORG\", \"PERSON\", \"GPE\", \"PRODUCT\", \"EVENT\"]\n",
    "\n",
    "# Add the labels to the NER component\n",
    "for label in LABELS:\n",
    "    ner.add_label(label)\n",
    "\n",
    "# Train the model\n",
    "optimizer = nlp.begin_training()\n",
    "for i in range(20):\n",
    "    random.shuffle(TRAIN_DATA)\n",
    "    losses = {}\n",
    "    for text, annotations in TRAIN_DATA:\n",
    "        nlp.update(\n",
    "            [text],  # batch of texts\n",
    "            [annotations],  # batch of annotations\n",
    "            drop=0.5,  # dropout - make it harder to memorise data\n",
    "            sgd=optimizer,  # callable to update weights\n",
    "            losses=losses)\n",
    "    print(losses)\n",
    "\n",
    "# Save the updated model to disk\n",
    "nlp.to_disk('/path/to/model')\n",
    "\n",
    "# Test the model on some new text\n",
    "test_text = \"Apple is going to build a factory in Mexico City.\"\n",
    "doc = nlp(test_text)\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
